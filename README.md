# [https://p4css.github.io/R1081/](https://p4css.github.io/R1081/)
- Syllabus (Google docs): [R1081](https://docs.google.com/document/d/1LfVUgcPkX1IMTm-o19dm7X_eUKn2HPGZiXlyIpcKQP4/edit?usp=sharing)
- [Weekly rundown slide link](https://docs.google.com/presentation/d/e/2PACX-1vRHPfKRHr_KckfO0blD-GrTOxj7Y3L3HiZQJUKFqm2ftWiI02949LVTJfS1uXgRxQMyy7rYr1-xDNlr/pub?start=false&loop=false&delayms=3000)


# Rundown
## Week 10. 
* **[Group up](https://docs.google.com/spreadsheets/d/1va9Knp793g0l0GidZbThvaGt12U0oZCmxFCqadQJC1Q/edit?usp=sharing)** !!!!!
* **AS#6** [Feature extraction of news headline for clickbait detection](https://drive.google.com/open?id=1vQ04p8Ylb9_hkRNRHIib7oj_ou-BPtj-Rb3GtK-27TQ)(Due: 11/20 23:59. Final Submission: 11/24 23:59)
* **Preview video before 11/18**: The links are shared to all participants. If you're enrolled students, you **MUST** go to NTU COOL to watch videos. Also, remember to submit your practice to NTU COOL.
  - [4_6 Chinese Information Retrieval](https://youtu.be/f2H6gq256uU): Filter words by word frequency, part-of-speech, stop words, and tf-idf.
  - [ML5.1 PCA Introduction](https://youtu.be/EpT-mk2V2-E)
  - [ML5.2 PCA on IRIS](https://youtu.be/pQaZlNRyhDk)
  - [ML5.3 PCA_fb_page_ideology](https://youtu.be/r7Q8CnDVI6c)

## Week 9. 20191104 Midterm break

## Week 8. 20191028
* **Midterm**
* **Preview video before 11/11**: The links are shared to all participants. If you're enrolled students, you **MUST** go to NTU COOL to watch videos. Also, remember to submit your practice to NTU COOL.
  - [3.5 Scraping ptt post](https://youtu.be/ncH9dhJi_-c)
  - [4.4.1 Tweet anaysis word level I](https://youtu.be/VzxzUVOkPf8)
  - [4.4.2 Tweet anaysis word level II](https://youtu.be/kCoeK77vnh8)
  - [4.5 Text analysis for Chinese text](https://youtu.be/TXp8VteXJdo)

## Week 7. 20191021
* **In-class slides and code**
* **AS#5**: Scraping online news (See more detail on NTU COOL). 
* **Preview video before 10/28**: The links are shared to all participants. If you're enrolled students, you **MUST** go to NTU COOL to watch videos. Also, remember to submit your practice to NTU COOL.
  - [4.1 Tweet analysis on trump tweets: Case Introduction](https://youtu.be/C4XU37Cbprk)
  - [4.2.1 Regular Expression Basic](https://youtu.be/exJF8AMyyzo)
  - [4.2.2 RE extract](https://youtu.be/eBESxOUNjRg)
  - [4.2.3 RE Applications](https://youtu.be/EAl-wzU3miE)
  - [4.3 Tweet analysis doc level (for RE & ggplot)](https://youtu.be/1FEdK5di0AQ)

## Week 6. 20191014 
* **In-class slides and code**
  - Reviewing the case paid maternal leave using dplyr by `R02_1p_readxl_paid_maternal_leave.Rmd`
  - Reviewing dplyr and pivot analysis by `R02_2p_pivot_on_tp_theft_dplyr.Rmd`
  - Reviewing joining data with PTT posts and comments by `InClass04_join_ptt_blank.Rmd`
* **AS#4**: Scraping ubike data and combining them for discovering usage trends of ubike site
  - Previewing AS#4 [AS04_scraping_json.html](https://p4css.github.io/R1081/AS04_scraping_json.html)
  - Download the repo and answer questions in `AS04_scraping_json.Rmd`
* **Preview video instruction before 10/21**: The links are shared to all participants. If you're enrolled students, you **MUST** go to NTU COOL to watch videos. Also, remember to submit your practice to NTU COOL.
  - [3.1 HTML Essentials](https://youtu.be/x9QhP8v0G6U)
  - [3.2 parse html get 1](https://youtu.be/nev71vayfN8)
  - [3.2 parse html get 2 ptt](https://youtu.be/l2Hx4tuZULg)
  - [3.3 ibon crawler POST](https://youtu.be/UY_mT0LJW3w)
  - [3.4 ptt_scraping_postlink_with_cookie](https://youtu.be/BdYE0lTSQQo)

## Week 5. 20191007
* **In-class slides and code**
  - **Practice: Joining demographic and referendum data** (for AS#3) open
* **AS#3**: Combining more data with referendum data (Due: 10/16 WED 23:59. Closed:10/20 SUN 23:59)
  - Previewing AS#3 [AS03_join_edu_data.html](https://p4css.github.io/R1081/AS03_join_edu_data.html)
  - Download the repo and answer questions in `AS03_join_edu_data.Rmd`
* **Preview video instruction before 10/14**: (The links are shared to all participants. If you're enrolled students, you **MUST** go to NTU COOL to watch videos)
  - [2.1 Introduction to JSON](https://youtu.be/NAwOobTPh8M)
  - [2.2 Hand-by-hand: Reading JSON](https://youtu.be/0RVvkveI_a8)
  - [2.3 Hand-by-hand: Reading JSON, more complicated cases](https://youtu.be/rS-GlEYuFE0)
  - [2.4 Using Chrome DevTools to find out data URL](https://youtu.be/P7DCgX0YAvM)
  - [2.5 Hand-by-hand: Scraping 104 job search](https://youtu.be/Tu63pSFrmM4)
* **Practice Week5 (At-Home) - Read JSON and Crawler Design**
  - Follow the instructions in the video and fill in the blank rmd files. `R02_4p_read_json.Rmd` and `R03_1p_crawl_104.Rmd`
  - Submitting these two .rmd files, and knitted .html files
  - Submitting before the start of the next week class (10/14 09:00). No delay.


## 20190930
* **Preview Datacamp before 10/07**
  - [String Manipulation in R with stringr](https://www.datacamp.com/courses/string-manipulation-in-r-with-stringr): Detecting, matching, splitting, replacing string with Regular expression.
  - [Data Visualization with ggplot2](https://www.datacamp.com/courses/data-visualization-with-ggplot2-1): You can also learn by case with the 2nd unit of Exploratory Data Analysis in R: Case Study. 


## 20190923
* **In-class slides and code**
  - **Reviewing slide [R01_2 R Basic](https://docs.google.com/presentation/d/e/2PACX-1vRjb_W1Vo9-zD9F4FmWOiB6K4ezkF6W64OKcX7bZD6ordKvOT-6LFoGi0le-HzT2ABKudDNhr_qKt2x/pub?start=false&loop=false&delayms=3000)** for [Assignment#1](https://p4css.github.io/R1081/AS01_R_Basic.html).\
  Code: [R01_2_vector.html](https://p4css.github.io/R1081/R01_2_vector.html), [R01_3_dataframe_import_export.html](https://p4css.github.io/R1081/R01_3_dataframe_import_export.html)
  - **Practice: Comparing base and dplyr:**\
  Slide [R02_1 Using R to analyze maternal leave](https://docs.google.com/presentation/d/e/2PACX-1vRDGlYA4GPhbgreLaJUXBIWPz0xmfT4pG40s4h4LXD7Gq5k65as5sAf_6-o7-WFKyTY5jOcWI_f77Sn/pub?start=false&loop=false&delayms=3000).\
  Code: [R02_1p_readxl_paid_maternal_leave.Rmd](R02_1p_readxl_paid_maternal_leave.Rmd)\
  (HTML: [R02_1_readxl_paid_maternal_leave.html](https://p4css.github.io/R02_1_readxl_paid_maternal_leave.html))
* **Assignment#2** [AS02_dplyr_ptt_result.html](https://p4css.github.io/R1081/AS02_dplyr_ptt_result.html): Following the assignment to detect questionable users or just big fans of the Kaohsiung Mayor Han. Answer the question directly in the AS#2 markdown file [AS02_prac01_dplyr_ptt_blank.Rmd](https://p4css.github.io/R1081/AS02_prac01_dplyr_ptt_blank.Rmd) in the repo. 
* **Preview Datacamp before 09/30** 
  - [Cleanning data in R](https://www.datacamp.com/courses/cleaning-data-in-r): `tidyr::gather()`, `tidyr::spread()`, `tidyr::separate()`, `Dealing with missing values`
  - [Joining Data with dplyr in R](https://www.datacamp.com/courses/joining-data-with-dplyr-in-r): `left_joing()`, `right_join()`, `full_join()`, `inner_join()`



## 20190916
* **In-class slides and code**
  - (Option) Slide [R01_1 Start R](https://docs.google.com/presentation/d/e/2PACX-1vR7PyAkfJBZq-LbZefnlbvlPhEbB2s1o5vQTabdEN5Fxa7PQwHv3eVgiQrpM1lkGsKrJ0xmya0l2ktj/pub?start=false&loop=false&delayms=3000): Installing R and RStudio, using RStudio, and editing R Markdown. Code: [R01_1_loading_data.html](R01_1_loading_data.html)
* **Assignment#1** [R Basic](AS01_R_Basic.html)([How to upload your first assignment](https://youtu.be/HHY5krhdWC4))
* **Preview Datacamp before 09/23**
  - [Importing Data in R (Part 1)](https://www.datacamp.com/courses/importing-data-in-r-part-1): `read.csv()`, `options(stringAsFactors = F)`, `read_csv()` with args: `skip` and `n_max`, and `library(readxl)`.
  - [Data Manipulation with dplyr in R](https://www.datacamp.com/courses/data-manipulation-with-dplyr-in-r): `glimpse()`, `select()`, `filter()`, `arrange()`, `mutate()`, `count()`, `group_by()`, `summarize()`, `transmnute()`


## 20190909
* Preview Datacamp before 09/16
  - [Introduction to R](https://www.datacamp.com/courses/free-introduction-to-r)
  - [Intermediate R](https://www.datacamp.com/courses/intermediate-r)

## Week 7. 20191021
* **AS#5**
  - (Focus on crawling html files)
  - For referendum data, joining town-level number of 7-11 store to referendum data.

## 20191028
* **In-class slides and code**
* **Assignment #7**: 
* **Preview video before**: 
